<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scribe v2 Realtime Test</title>
    <style>
        body { 
            font-family: sans-serif; 
            padding: 20px; 
            max-width: 800px; 
            margin: 0 auto; 
            background: #f5f5f5;
        }
        button { 
            padding: 10px 20px; 
            font-size: 16px; 
            cursor: pointer; 
            border: none;
            border-radius: 4px;
            background: #6366f1;
            color: white;
            margin: 5px;
        }
        button:hover {
            background: #4f46e5;
        }
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        #status { 
            margin-top: 10px; 
            font-weight: bold; 
            color: #555; 
            padding: 10px;
            background: white;
            border-radius: 4px;
        }
        #transcript { 
            margin-top: 20px; 
            white-space: pre-wrap; 
            border: 1px solid #ccc; 
            padding: 10px; 
            min-height: 100px; 
            background: white;
            border-radius: 4px;
        }
        .partial { 
            color: #888; 
            font-style: italic; 
        }
        .final { 
            color: #000; 
        }
        input[type="password"] {
            width: 300px;
            padding: 8px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 14px;
        }
        .info-box {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
        }
    </style>
</head>
<body>

    <h1>Scribe v2 Realtime Testing</h1>
    
    <div class="info-box">
        <strong>Implementation Guide:</strong> This example demonstrates microphone access, 
        16kHz audio downsampling, and WebSocket streaming to ElevenLabs Scribe v2.
    </div>
    
    <label for="apiKey">API Key:</label>
    <input type="password" id="apiKey" placeholder="Enter ElevenLabs API Key" style="width: 300px; padding: 5px;">
    
    <br><br>

    <button id="startBtn">Start Streaming</button>
    <button id="stopBtn" disabled>Stop</button>

    <div id="status">Status: Ready</div>
    <div id="transcript"></div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
        const apiKeyInput = document.getElementById('apiKey');

        let socket;
        let audioContext;
        let processor;
        let source;
        let mediaStream;
        let isRecording = false;

        // Configuration for Scribe v2
        const SAMPLE_RATE = 16000; // Scribe v2 requires 16kHz PCM
        
        startBtn.onclick = async () => {
            const apiKey = apiKeyInput.value.trim();
            if (!apiKey) {
                alert("Please enter your API Key");
                return;
            }

            try {
                statusDiv.textContent = "Status: Connecting...";
                
                // 1. Initialize WebSocket Connection
                // Using the specific Scribe v2 Realtime endpoint with query params
                // Note: Browser WebSockets cannot set custom headers, so we use query parameter
                const wsUrl = `wss://api.elevenlabs.io/v1/speech-to-text/realtime?model_id=scribe_v2_realtime&audio_format=pcm_16000&xi_api_key=${encodeURIComponent(apiKey)}`;
                
                socket = new WebSocket(wsUrl);

                // Handle WebSocket Open
                socket.onopen = async () => {
                    statusDiv.textContent = "Status: Connected! Starting audio capture...";
                    
                    // 2. Start Microphone and Audio Processing
                    await startAudioCapture();
                    isRecording = true;
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    statusDiv.textContent = "Status: Connected & Streaming...";
                };

                socket.onmessage = (event) => {
                    try {
                        const response = JSON.parse(event.data);
                        
                        // Handle Partial Transcripts
                        if (response.type === "partial_transcript" || response.type === "partial_transcription") {
                            const partialText = response.text || response.transcript || "";
                            if (partialText) {
                                // Update partial transcript display
                                updatePartialTranscript(partialText);
                            }
                        }
                        
                        // Handle Final/Committed Transcripts
                        if (response.type === "final_transcript" || 
                            response.type === "final_transcription" ||
                            response.type === "word" || 
                            response.message_type === "committed_transcript_with_timestamps") {
                            const finalText = response.text || response.transcript || "";
                            if (finalText) {
                                appendFinalTranscript(finalText);
                            }
                        }
                        
                        // Log all messages for debugging
                        console.log("Received:", response);
                    } catch (error) {
                        console.error("Failed to parse WebSocket message:", error);
                    }
                };

                socket.onerror = (error) => {
                    console.error("WebSocket Error:", error);
                    statusDiv.textContent = "Status: Error (Check console)";
                };

                socket.onclose = (event) => {
                    if (isRecording) stopRecording();
                    statusDiv.textContent = `Status: Disconnected (Code: ${event.code})`;
                };

            } catch (err) {
                console.error(err);
                statusDiv.textContent = "Status: Error initializing audio";
            }
        };

        stopBtn.onclick = () => {
            stopRecording();
        };

        function stopRecording() {
            isRecording = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;

            if (socket && socket.readyState === WebSocket.OPEN) {
                // Send End of Stream message if required, or just close
                // socket.send(JSON.stringify({ type: "end_of_stream" })); 
                socket.close();
            }
            
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            
            if (source) {
                source.disconnect();
                source = null;
            }
            
            if (audioContext) {
                audioContext.close().catch(() => {});
                audioContext = null;
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            statusDiv.textContent = "Status: Stopped";
        }

        async function startAudioCapture() {
            try {
                // Request microphone access
                mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        channelCount: 1,
                        sampleRate: SAMPLE_RATE  // Request 16kHz (may not be honored)
                    }
                });
                
                // Create AudioContext at 16kHz
                // CRITICAL: Explicitly set sample rate to 16kHz
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ 
                    sampleRate: SAMPLE_RATE 
                });
                
                // Log actual sample rate (may differ from requested)
                console.log('Requested sample rate:', SAMPLE_RATE);
                console.log('Actual sample rate:', audioContext.sampleRate);
                
                if (audioContext.sampleRate !== SAMPLE_RATE) {
                    console.warn(`Warning: Actual sample rate is ${audioContext.sampleRate}Hz, not ${SAMPLE_RATE}Hz. Manual resampling may be required.`);
                }
                
                // Create source from microphone stream
                source = audioContext.createMediaStreamSource(mediaStream);
                
                // Create a ScriptProcessorNode to capture audio in real-time
                // Buffer size 4096 is a good balance between latency and performance
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                source.connect(processor);
                processor.connect(audioContext.destination); // Required to activate processor

                processor.onaudioprocess = (e) => {
                    if (!isRecording || socket.readyState !== WebSocket.OPEN) return;

                    const inputData = e.inputBuffer.getChannelData(0);
                    
                    // Convert Float32 audio to Int16 PCM (required by ElevenLabs)
                    const pcmData = floatTo16BitPCM(inputData);
                    
                    // Convert to Base64
                    const base64Audio = arrayBufferToBase64(pcmData);

                    // Send to Scribe v2
                    // The message format is strictly JSON for Scribe v2
                    const message = {
                        "message_type": "input_audio_chunk",
                        "audio_base_64": base64Audio,
                        "commit": false // Set to true if you want to force commit, usually false for streaming
                    };
                    
                    socket.send(JSON.stringify(message));
                };
                
            } catch (error) {
                console.error('Failed to start audio capture:', error);
                throw error;
            }
        }

        // Helper: Convert Float32 (Browser Audio) to Int16 (PCM)
        function floatTo16BitPCM(input) {
            let output = new Int16Array(input.length);
            for (let i = 0; i < input.length; i++) {
                // Clamp value between -1 and 1
                let s = Math.max(-1, Math.min(1, input[i]));
                // Convert to 16-bit integer
                // Negative values: multiply by 0x8000 (32768)
                // Positive values: multiply by 0x7FFF (32767)
                output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            return output.buffer; // Return ArrayBuffer
        }

        // Helper: ArrayBuffer to Base64
        function arrayBufferToBase64(buffer) {
            let binary = '';
            let bytes = new Uint8Array(buffer);
            let len = bytes.byteLength;
            for (let i = 0; i < len; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            return window.btoa(binary);
        }
        
        // Update partial transcript (replaces previous partial)
        function updatePartialTranscript(text) {
            // Remove previous partial transcripts
            const partialElements = transcriptDiv.querySelectorAll('.partial');
            partialElements.forEach(el => el.remove());
            
            // Add new partial transcript
            if (text) {
                const partialSpan = document.createElement('span');
                partialSpan.className = 'partial';
                partialSpan.textContent = text + ' ';
                transcriptDiv.appendChild(partialSpan);
            }
        }
        
        // Append final transcript
        function appendFinalTranscript(text) {
            // Remove any partial transcripts
            const partialElements = transcriptDiv.querySelectorAll('.partial');
            partialElements.forEach(el => el.remove());
            
            // Add final transcript
            if (text) {
                const finalSpan = document.createElement('span');
                finalSpan.className = 'final';
                finalSpan.textContent = text + ' ';
                transcriptDiv.appendChild(finalSpan);
            }
        }
    </script>
</body>
</html>
